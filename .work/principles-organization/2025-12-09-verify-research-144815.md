# Research Report: Organizing 7 Development Principles into 3 Core Principles

## Metadata
- Date: 2025-12-09
- Researcher: research-agent
- Scope: Analysis of principle grouping patterns from software engineering literature, cognitive psychology (rule of three), and CipherPowers codebase context

## Research Questions
1. How do industry frameworks organize software development principles?
2. What does cognitive psychology tell us about organizing 7 items into 3?
3. What are the natural relationships between the current 7 principles?
4. What grouping patterns emerge from software craftsmanship literature?
5. How should taglines work to be memorable and instructive?

## Key Findings

### Finding 1: Cognitive Psychology - Rule of Three
- **Source:** Multiple cognitive psychology studies (Cowan, Miller, Google Design, Flow Research Collective)
- **Evidence:**
  - Working memory holds 3-4 items optimally (Cowan)
  - George Miller's "7Â±2" refined to 3-4 for active manipulation
  - Rule of three eliminates "weak middle" via primacy/recency effects
  - U.S. Marines found rule of 4 decreased effectiveness, reverted to 3
  - "Omne trium perfectum" (everything in threes is perfect) - Ancient Rome
- **Confidence:** HIGH
- **Implication:** Three top-level principles maximize memorability and cognitive efficiency. Seven principles exceed optimal working memory capacity.

### Finding 2: Industry Patterns - Three-Pillar Frameworks
- **Source:** Software craftsmanship, QA literature, agile practices
- **Evidence:**
  - **Three Pillars of Agile QA:** Cross-functional practices, Development/automation, [third varies by source]
  - **Three Pillars of Software QA (Medium):** Coaching, Support, Verification
  - **Software Craftsmanship Manifesto areas:** Technical excellence, Collaboration, Individual/collective responsibility
  - **Robert C. Martin themes:** Simplicity, Testing, Collaboration
- **Confidence:** MEDIUM-HIGH
- **Implication:** Industry already organizes quality principles into three areas: (1) How code is written, (2) How code is verified, (3) How teams work together

### Finding 3: SOLID Principles Organization
- **Source:** Robert C. Martin, Clean Architecture literature
- **Evidence:**
  - SOLID creates "mid-level software structures that: tolerate change, are easy to understand, serve as basis of components"
  - Three goals map to: Changeability (OCP, DIP), Understandability (SRP, ISP), Componentization (LSP)
  - Clean Architecture layers separate: Business logic (core), Technical implementation (outer), Delivery mechanisms
- **Confidence:** HIGH
- **Implication:** Principle organization should reflect *purpose domains* not just *activity types*

### Finding 4: Current 7 Principles - Natural Groupings
- **Source:** `/Users/tobyhede/src/cipherpowers/plugin/principles/development.md`
- **Evidence:** Analyzing relationships between principles:

  **Craft Quality (How Code Looks/Feels):**
  - Simple (not clever) - code structure
  - Consistent (not stamped with individuality) - code patterns
  - Documented (with the why) - code understanding

  **Verification Quality (How We Know It Works):**
  - Tested (behavior, not implementation) - automated verification
  - Debugged (root cause, not symptoms) - investigative verification
  - Validated (at every layer) - defensive verification

  **Collaboration Quality (How We Work Together):**
  - Reviewed (technical correctness over social comfort) - peer verification

- **Confidence:** HIGH
- **Implication:** Principles naturally cluster into: Writing (3), Verification (3), Collaboration (1). This is unbalanced.

### Finding 5: Alternative Grouping - Process-Based
- **Source:** Analysis of code review standards, TDD skills, debugging skills in codebase
- **Evidence:**
  - Code review standards emphasize "technical correctness over social comfort"
  - TDD skills enforce "test before implementation"
  - Debugging skills require "root cause over symptoms"
  - All three share: *Rigor over convenience*

  **Discipline Pattern:**
  - Tested (behavior, not implementation) - TDD discipline
  - Debugged (root cause, not symptoms) - Investigation discipline
  - Reviewed (technical correctness over social comfort) - Review discipline

- **Confidence:** MEDIUM-HIGH
- **Implication:** Could organize around *when* principles apply: Before coding, During coding, After coding

### Finding 6: CipherPowers-Specific Context
- **Source:** Plugin architecture, persuasion principles, code-agent requirements
- **Evidence:**
  - Code-agent MUST read development.md principles before proceeding
  - Persuasion principles emphasize Authority + Commitment for discipline-enforcing content
  - Plugin architecture separates: Skills (how), Commands (when), Agents (who)
  - Testing principles separated into standalone `/plugin/principles/testing.md` (no longer exists, deleted)
- **Confidence:** HIGH
- **Implication:** Principles serve as *authority reference* for agents. Must be clear, imperative, memorable.

### Finding 7: Tagline Pattern Analysis
- **Source:** Current principles, persuasion principles, cognitive psychology
- **Evidence:**
  - Current taglines use "(not X)" pattern: "Simple (not clever)", "Consistent (not stamped with individuality)"
  - Pattern creates clear contrast and memorable opposition
  - Persuasion research shows contrasts increase recall
  - Taglines should be short (3-5 words after principle name)
- **Confidence:** HIGH
- **Implication:** Keep "(not X)" pattern for memorability. Tagline should capture the *violation* to avoid.

## Patterns Observed

### Pattern 1: Three-Part Industry Standards
Across software engineering literature, quality frameworks consistently organize into three domains:
1. **Code/Design quality** (how we write)
2. **Verification quality** (how we validate)
3. **People/Process quality** (how we collaborate)

### Pattern 2: Craft vs. Discipline Divide
Principles split naturally into:
- **Craft principles:** What good code looks like (Simple, Consistent, Documented)
- **Discipline principles:** What rigorous process requires (Tested, Debugged, Validated, Reviewed)

### Pattern 3: Lifecycle Mapping
Principles map to software development lifecycle:
- **Before/During coding:** Simple, Consistent, Documented
- **During/After coding:** Tested, Debugged, Validated
- **Before merge:** Reviewed

### Pattern 4: Individual vs. Team Scope
- **Individual practices:** Simple, Consistent, Documented, Tested, Debugged, Validated
- **Team practices:** Reviewed

This suggests "Reviewed" might belong under a collaboration/team umbrella.

## Gaps and Uncertainties

### Gap 1: Validation vs. Testing Distinction
- Testing and Validation overlap significantly
- Both verify correctness, but at different layers
- Unclear if these should be separate top-level concerns or sub-concerns of same principle
- Industry literature doesn't clearly distinguish these as separate pillars

### Gap 2: Documentation as Standalone Principle
- Some frameworks include documentation under "Clarity" or "Maintainability"
- Others treat it as separate concern
- CipherPowers emphasizes "why not what" - this is craft quality, not just documentation
- Could documentation be subsumed under "Understandable" or "Clear"?

### Gap 3: Debugging vs. Testing Relationship
- Both are verification activities
- Debugging is reactive (fix problems), Testing is proactive (prevent problems)
- Could these be two sides of same principle: "Verified"?
- Or are they different enough (proactive vs. reactive) to warrant separation?

### Gap 4: Review as Collaboration vs. Verification
- Code review serves dual purpose: verification + knowledge sharing
- Could belong under "Verification" pillar OR "Collaboration" pillar
- Industry literature splits on this
- CipherPowers context emphasizes technical correctness (verification) over social aspects

### Gap 5: Missing Explicit Security/Performance Principles
- Current 7 don't explicitly mention security or performance
- Code review standards heavily emphasize these (BLOCKING issues)
- Are these covered implicitly by "Validated" or "Tested"?
- Industry frameworks often include these explicitly

### Gap 6: Tagline Effectiveness Testing
- No empirical data on which taglines are most memorable
- Current taglines not tested with actual developers
- Cannot verify which contrasts ("not clever" vs. "not complex") work best
- Psychological theory supports contrast, but specific wording uncertain

## Grouping Options Analysis

### Option A: Craft + Verification + Collaboration (Activity-Based)

**Structure:**
1. **Crafted** (not chaotic)
   - Simple (not clever)
   - Consistent (not stamped with individuality)
   - Documented (with the why)

2. **Verified** (not assumed)
   - Tested (behavior, not implementation)
   - Debugged (root cause, not symptoms)
   - Validated (at every layer)

3. **Reviewed** (technical correctness over social comfort)
   - [Currently standalone]

**Strengths:**
- Natural grouping based on current 7
- Clear separation of concerns
- Aligns with code review checklist structure

**Weaknesses:**
- "Reviewed" feels thin as standalone principle
- Unbalanced (3-3-1 split)
- Doesn't leverage collaboration as team practice

**Confidence:** MEDIUM - Logical but imbalanced

---

### Option B: Design + Discipline + Defense (Purpose-Based)

**Structure:**
1. **Designed** (not emerged)
   - Simple (not clever)
   - Consistent (not stamped with individuality)
   - Documented (with the why)

2. **Disciplined** (not convenient)
   - Tested (behavior, not implementation)
   - Debugged (root cause, not symptoms)
   - Reviewed (technical correctness over social comfort)

3. **Defended** (not fragile)
   - Validated (at every layer)
   - [Could add: Secured, Resilient sub-principles]

**Strengths:**
- Balanced 3-3-1 (or 3-3-2 with expansion)
- Clear purpose for each pillar
- "Disciplined" captures rigor theme
- "Defended" captures defense-in-depth

**Weaknesses:**
- "Defended" requires expanding beyond current 7
- "Designed" might imply up-front design (conflicts with TDD/emergent design)
- "Reviewed" under "Disciplined" loses collaborative aspect

**Confidence:** MEDIUM - Requires adding new sub-principles

---

### Option C: Clarity + Correctness + Rigor (Quality-Based)

**Structure:**
1. **Clear** (not clever)
   - Simple (not clever)
   - Consistent (not stamped with individuality)
   - Documented (with the why)

2. **Correct** (not assumed)
   - Tested (behavior, not implementation)
   - Validated (at every layer)
   - Reviewed (technical correctness over social comfort)

3. **Rigorous** (not convenient)
   - Debugged (root cause, not symptoms)
   - [Principles about process discipline]

**Strengths:**
- Quality-focused (aligns with "quality gates" plugin feature)
- "Clear" is more accurate than "Simple" (encompasses all 3 sub-items)
- "Correct" captures verification domain
- "Rigorous" captures process discipline

**Weaknesses:**
- "Rigorous" feels overlapping with "Correct"
- Debugging under "Rigorous" separate from Testing under "Correct" feels arbitrary
- Testing and Debugging both verify correctness but split across pillars

**Confidence:** LOW - Overlapping concerns, arbitrary splits

---

### Option D: Understandable + Dependable + Collaborative (Outcome-Based)

**Structure:**
1. **Understandable** (not clever)
   - Simple (not clever)
   - Consistent (not stamped with individuality)
   - Documented (with the why)

2. **Dependable** (not assumed)
   - Tested (behavior, not implementation)
   - Debugged (root cause, not symptoms)
   - Validated (at every layer)

3. **Collaborative** (honesty over comfort)
   - Reviewed (technical correctness over social comfort)
   - [Could add: Shared ownership, Knowledge transfer]

**Strengths:**
- Outcome-focused (user perspective)
- "Understandable" captures why clarity matters
- "Dependable" captures why verification matters
- "Collaborative" captures team/culture aspect
- Aligns with Software Craftsmanship Manifesto themes
- Balanced if expanded (3-3-2)

**Weaknesses:**
- "Collaborative" thin with only Review
- "Dependable" doesn't capture defense-in-depth as clearly as "Defended"
- Outcome-based may be less actionable than activity-based

**Confidence:** MEDIUM-HIGH - Well-balanced, outcome-focused, but needs expansion

---

### Option E: Written + Verified + Evolved (Lifecycle-Based)

**Structure:**
1. **Written** (craft over convenience)
   - Simple (not clever)
   - Consistent (not stamped with individuality)
   - Documented (with the why)

2. **Verified** (evidence over assumption)
   - Tested (behavior, not implementation)
   - Debugged (root cause, not symptoms)
   - Validated (at every layer)

3. **Evolved** (rigor over speed)
   - Reviewed (technical correctness over social comfort)
   - [Could add: Refactored, Maintained]

**Strengths:**
- Lifecycle-based (when principles apply)
- "Written" clear and concrete
- "Verified" captures all verification activities
- "Evolved" captures continuous improvement

**Weaknesses:**
- "Written" doesn't convey quality (just activity)
- "Evolved" weak without expansion
- Lifecycle framing may not match team mental models

**Confidence:** LOW-MEDIUM - Logical structure but weak taglines

---

### Option F: Readable + Reliable + Rigorous (The Three Rs)

**Structure:**
1. **Readable** (not clever)
   - Simple (not clever)
   - Consistent (not stamped with individuality)
   - Documented (with the why)

2. **Reliable** (not fragile)
   - Tested (behavior, not implementation)
   - Validated (at every layer)
   - Debugged (root cause, not symptoms)

3. **Rigorous** (not convenient)
   - Reviewed (technical correctness over social comfort)
   - [Could add: Measured, Verified sub-principles]

**Strengths:**
- Memorable alliteration (Three Rs)
- "Readable" directly captures maintainability goal
- "Reliable" captures why verification matters
- "Rigorous" captures process discipline

**Weaknesses:**
- "Rigorous" overlaps with verification in "Reliable"
- "Rigorous" thin with only Review
- Alliteration might feel gimmicky

**Confidence:** MEDIUM - Memorable but needs better distinction between Reliable/Rigorous

## Recommended Grouping Options (Ranked)

### Rank 1: Option D (Understandable + Dependable + Collaborative)
**Rationale:**
- Outcome-based framing matches user/team perspective
- Best aligns with Software Craftsmanship literature
- Clear separation of concerns
- "Collaborative" captures cultural/team aspect missing from other options
- Can expand "Collaborative" with knowledge sharing, ownership principles

**Expansion needed:**
- Add sub-principles under Collaborative (e.g., "Share knowledge", "Own quality collectively")

---

### Rank 2: Option B (Designed + Disciplined + Defended)
**Rationale:**
- Purpose-based framing is actionable
- "Disciplined" strongly captures rigor theme
- "Defended" captures defense-in-depth from validation skills
- Good balance possible with expansion

**Concerns:**
- "Designed" may imply waterfall/up-front design (conflicts with emergent design/TDD)
- Requires adding security/resilience sub-principles under "Defended"

---

### Rank 3: Option A (Crafted + Verified + Reviewed)
**Rationale:**
- Most natural given current 7 principles
- Minimal reorganization required
- Clear activity-based separation

**Concerns:**
- "Reviewed" too thin as standalone
- Misses opportunity to emphasize collaboration/culture
- Imbalanced structure

---

### Rank 4: Option F (Readable + Reliable + Rigorous)
**Rationale:**
- Memorable alliteration
- Quality-focused outcomes
- "Readable" excellent capture of craft quality

**Concerns:**
- "Rigorous" overlaps with "Reliable"
- Distinction between Reliable/Rigorous unclear
- Needs better separation of verification types

## Summary

The research reveals three key insights:

1. **Cognitive science supports 3 principles:** Working memory research consistently shows 3-4 items is optimal for active manipulation. Rule of three eliminates weak middle via primacy/recency effects.

2. **Industry uses three-pillar frameworks:** Software craftsmanship, QA, and agile literature consistently organize around three domains - typically: code quality, verification, and collaboration/process.

3. **Current 7 principles cluster naturally:** The existing principles show strong grouping into craft (Simple/Consistent/Documented) and verification (Tested/Debugged/Validated), with Review as outlier.

**Top recommendation:** Organize around **Understandable + Dependable + Collaborative** (Option D). This outcome-based framing aligns with Software Craftsmanship literature, balances technical and cultural concerns, and can expand to include knowledge sharing and collective ownership under Collaborative.

**Alternative:** **Designed + Disciplined + Defended** (Option B) offers purpose-based framing with strong rigor emphasis, but requires expanding "Defended" with security/resilience principles.

## Recommendations

1. **Choose Option D (Understandable + Dependable + Collaborative)** as primary grouping
   - Expand "Collaborative" with 2-3 sub-principles (knowledge sharing, collective ownership)
   - Outcome-based framing most aligned with user perspective

2. **Maintain "(not X)" tagline pattern** for memorability and contrast

3. **Test taglines with actual developers** before finalizing (current gap in research)

4. **Consider security/performance explicitly** - currently implicit, may need explicit sub-principles

5. **Use authority language in documentation** - aligns with persuasion research and CipherPowers agent architecture

## Research Sources

### Cognitive Psychology
- [Rule of Three Psychology: Cognitive Processing in Triads](https://neurolaunch.com/rule-of-three-psychology/)
- [The Rule Of Three & The Brain - Flow Research Collective](https://www.flowresearchcollective.com/blog/the-rule-of-three-the-brain)
- [Want Your Presentation to Be Memorable? Follow the Rule of Three](https://www.mandel.com/blog/want-your-presentation-to-be-memorable-follow-the-rule-of-three)
- [Rule of Three: Design for User Clarity - Google Design](https://design.google/library/rule-of-three)

### Software Engineering Principles
- [Seven Basic Principles of Good Software Engineering - DZone](https://dzone.com/articles/7-basic-principles-of-good-software-engineering)
- [Top 10 Software Engineering Principles - Full Scale](https://fullscale.io/blog/software-engineering-principles/)
- [Clean Code Principles: Writing Maintainable and Scalable Software](https://www.javacodegeeks.com/2025/02/clean-code-principles-writing-maintainable-and-scalable-software.html)

### SOLID and Clean Architecture
- [A Deep Dive into Clean Architecture and Solid Principles](https://medium.com/@unaware_harry/a-deep-dive-into-clean-architecture-and-solid-principles-dcdcec5db48a)
- [Understanding SOLID Principles and Clean Architecture](https://www.yourteaminindia.com/blog/understanding-solid-principles-and-clean-architecture)
- [SOLID Design Principles Explained - DigitalOcean](https://www.digitalocean.com/community/conceptual-articles/s-o-l-i-d-the-first-five-principles-of-object-oriented-design)

### Software Craftsmanship
- [The Principles of Craftsmanship - Clean Coder Blog - Uncle Bob](https://blog.cleancoder.com/uncle-bob/2013/02/10/ThePrinciplesOfCraftsmanship.html)
- [Software Craftsmanship: Principles vs. Tools](https://daily.dev/blog/software-craftsmanship-principles-vs-tools)
- [Software craftsmanship and its principles - Adesso](https://www.adesso.de/en/news/blog/software-craftsmanship-and-its-principles-2.jsp)

### Quality Assurance
- [The Three Pillars of Software QA](https://medium.com/@ss-tech/the-three-pillars-of-software-qa-coaching-support-and-verification-845bcdd64e8a)
- [QA, QC, and Testing: The Three Pillars of Software Quality Management](https://medium.com/@IntelliSoft/qa-qc-and-testing-the-three-pillars-of-software-quality-management-15f4a658fe20)
- [The Three Pillars of Agile Quality and Testing](https://www.techwell.com/techwell-insights/2015/04/three-pillars-agile-quality-and-testing-pillars-explained)

### Codebase Files
- `/Users/tobyhede/src/cipherpowers/plugin/principles/development.md`
- `/Users/tobyhede/src/cipherpowers/plugin/standards/code-review.md`
- `/Users/tobyhede/src/cipherpowers/plugin/agents/code-agent.md`
- `/Users/tobyhede/src/cipherpowers/plugin/skills/writing-skills/persuasion-principles.md`
